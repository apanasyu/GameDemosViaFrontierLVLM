# GameDemosViaFrontierLVLM
AI Model Game Dev Showdown: A practical benchmark for code generation. This project tests frontier AI models (Grok, Gemini, GPT, etc.) by prompting them to create playable games from scratch using Python and Pygame. Each model's generated code is run, recorded, and shared to compare their real-world coding abilities.

# AI Model Game Dev Showdown

 <!-- Optional: Create a cool banner for your project -->

A project to benchmark and compare the code generation abilities of frontier and open-source AI models. We test models like **Grok 4**, **Gemini Pro 2.5**, **GPT-5**, and others by tasking them with a simple, practical challenge: create a complete, playable game using Python and the Pygame library.

The goal is to move beyond theoretical benchmarks and see how well these models perform on a real-world, end-to-end creative and logical task.

## The Workflow

This project follows a consistent and transparent workflow to ensure a fair comparison between models.

### 1. Game Concept Generation
To avoid bias in the game description, we begin by asking a baseline model (currently Gemini Pro) for a detailed description of a classic game (e.g., Tetris, Snake, Pong). This description forms the core of our prompt.

### 2. Prompt Engineering
A standardized prompt is created for each game. The prompt is designed to give every model the same starting context and instructions. It always follows this structure:

```
I want to design a game, I would like to do it using library pygame (I have everything setup for this already), I want to start in Pycharm Community edition using: if __name__ == "__main__": main()

[Detailed description of the game from Step 1 is inserted here.]
```

### 3. Code Generation
The exact same prompt from Step 2 is then fed into a new, clean chat session for each of the models being tested. We currently plan to test:
*   Gemini Pro 2.5 (or latest)
*   Grok 4 (or latest)
*   GPT-5 (or latest)
*   Leading Open Source Models (e.g., Llama, Mistral)

### 4. Implementation & Archiving
The raw, unedited Python code generated by each model is saved into a dedicated file. The project is organized by game, with each folder containing the prompt and the code from each model. This ensures full transparency and reproducibility. All generated code is run using **Python 3.x** and **Pygame**.

### 5. Evaluation & Showcase
Finally, we run the code. The resulting gameplay (or lack thereof) is recorded in a short video clip (under 5 minutes) and uploaded to our [**YouTube Channel**](https://www.youtube.com/your-channel-link-here). This provides a clear, visual demonstration of the model's success, errors, and overall "understanding" of the task.

## Project Structure

The repository is organized by the game being tested. Each game has its own folder containing the prompt used and the resulting code from each AI model.

```
.
├── tetris/
│   ├── prompt.txt
│   ├── tetris_GeminiPro.py
│   ├── tetris_Grok4.py
│   ├── tetris_GPT5.py
│   └── ...
├── snake/
│   ├── prompt.txt
│   ├── snake_GeminiPro.py
│   ├── snake_Grok4.py
│   └── ...
├── README.md
└── .gitignore
```

## Results & Analysis

Here we will track the results of each test.

| Game      | Model          | Code Link                               | Gameplay Video | Status & Notes                                           |
| :-------- | :------------- | :-------------------------------------- | :------------- | :------------------------------------------------------- |
| **Tetris**  | Gemini Pro 2.5 | [Link](./tetris/tetris_GeminiPro.py)    | [Watch](https://youtube.com/link) | `Fully Functional` - Game works as expected.             |
| **Tetris**  | Grok 4         | [Link](./tetris/tetris_Grok4.py)        | [Watch](https://youtube.com/link) | `Minor Bugs` - Scoring system does not work correctly.   |
| **Tetris**  | GPT-5          | [Link](./tetris/tetris_GPT5.py)         | [Watch](https://youtube.com/link) | `Crashes on Start` - Fails to initialize the game board. |
| **Snake**   | ...            | ...                                     | ...            | ...                                                      |

*(This table will be updated as new tests are completed.)*

## How to Contribute

Contributions are welcome! If you have suggestions or want to help, here are a few ways:
*   **Suggest a Game:** Open an issue to suggest a new game to test the models on.
*   **Test a New Model:** If you have access to a new frontier or open-source model, feel free to run a test using an existing prompt and submit a pull request with the results.
*   **Bug Fixes:** While the goal is to test the *raw* output, a separate folder for "community-fixed" versions could be interesting. Feel free to discuss this in an issue.
*   **Improve Documentation:** Notice a typo or an unclear section in this README? Feel free to submit a PR!

## License

This project is licensed under the [MIT License](LICENSE). All generated code remains the intellectual property of its respective generating entity, shared here for educational and research purposes.
